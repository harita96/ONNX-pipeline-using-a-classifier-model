{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract - \n",
    " Build a ONNX pipeline, using a classifier model and feature engineering. The generated .ONNX file is then deployed and run on an actual data set to produce results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:\n",
    " Given a dataset need to build an efficient model and onnx file using the pipeline. The data is processed and imputed with mean of the individual columns. Then Random Forest model is build for this given dataset. The output of the project will be an .onnx file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Processing:\n",
    " The data in the given dataset has significant amount of negative values for every features and 15 features. The data is imputed with mean of each column.An sklearn pipeline is build, with column transformation and classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis:\n",
    " All the features are highly corrrelated. An correlation plot is plotted. The best features are selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training:\n",
    " The model chosen for this data set is Random Forest. This model is a fast model, it avoids over-fitting the data. The hyper-tuning parameters used to tune the model are:\n",
    "\n",
    " <li> max_depth=2 -> The maximum depth of the tree.</li>\n",
    " <li> n_estimators=1000  -> The number of trees in the forest.</li>\n",
    " <li> n_jobs=-1  -> The number of jobs to run in parallel for both fit and predict. </li>\n",
    " <li> criterion='gini' -> The function to measure the quality of a split.</li>\n",
    " <li> random_state=42  -> If int, random_state is the seed used by the random number generator.</li>\n",
    " <li> max_features= 2 -> The number of features to consider when looking for the best split.</li>\n",
    " <li> max_leaf_nodes=2 -> Grow trees with max_leaf_nodes in best-first fashion.</li>\n",
    "The data set was spilt according to stratified sampling using 'StratifiedShuffleSplit', with k-folds =6.The data was split into training and testing(validation) data set in 70:30 ratio. The model was then trained using the training data. The most important features of the model were identified. The 'SelectFromModel' function was used to select the best features from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Validation:\n",
    " The model was validated using the testing data set that was out-of-sample data from the stratified sampling that was not used during the model training. The accuracy and f1 score was calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    " The model was built was random forest. The tuning parameters are 'max_depth', 'n_estimators', 'criterion', 'random_state', 'max_features', 'max_leaf_nodes'. The pipeline was setup to pre-process the data from the file and impute its values and passed to the model built. The accuracy and f1 score of the model was calculated accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Sources:\n",
    " The CSV file was provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source Code:\n",
    " The references for random forest model building and parameter tuning are taken from these links below:\n",
    "https://www.datacamp.com/community/tutorials/random-forests-classifier-python\n",
    "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n",
    "https://chrisalbon.com/machine_learning/trees_and_forests/feature_selection_using_random_forest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliography:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html\n",
    "https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
